train_dir='/content/drive/My Drive/Colab Notebooks/convTasNet/train/stream_data/outdata/tr'

tr_dataset = AudioDataset(train_dir, batch_size,sample_rate=sample_rate, segment=segment)
# cv_dataset = AudioDataset(valid_dir, batch_size=1,sample_rate=sample_rate, segment=-1, cv_maxlen=cv_maxlen)
tr_loader = AudioDataLoader(tr_dataset, batch_size=1, shuffle=shuffle, num_workers=num_workers)
# cv_loader = AudioDataLoader(cv_dataset, batch_size=1,num_workers=0)

# data = {'tr_loader': tr_loader, 'cv_loader': cv_loader}
# tr_loader = data['tr_loader']
# cv_loader = data['cv_loader']
##########################################################
use_cuda=1
mask_nonlinear='relu'
model = ConvTasNet(N, L, B, H, P, X, R, C, 
                       norm_type=norm_type, causal=causal,
                       mask_nonlinear=mask_nonlinear)
max_norm=5
optimizer = torch.optim.SGD(model.parameters(),
                                      lr=lr,
                                      weight_decay=l2)
# print(model)
if use_cuda:
  model = torch.nn.DataParallel(model)
  model.cuda()
start = time.time()
total_loss = 0
epochs=100
LOSS=[]
################Train#####################################
for epoch in range(epochs):
  print("Training...")
  model.train()  # Turn on BatchNorm & Dropout
  start = time.time()
################run one epoch:######################
  data_loader=tr_loader
  for i, (data) in enumerate(data_loader):
    print(i)
  # print(data)
    padded_mixture, mixture_lengths, padded_source = data
    if use_cuda:
      padded_mixture = padded_mixture.cuda()
      mixture_lengths = mixture_lengths.cuda()
      padded_source = padded_source.cuda()
      estimate_source = model(padded_mixture)
    
    loss, max_snr, estimate_source, reorder_estimate_source =  cal_loss(padded_source, estimate_source, mixture_lengths)
  #           if not cross_valid:
    LOSS.append(loss)
    optimizer.zero_grad()
    loss.backward()
    torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm)
    optimizer.step()
    total_loss += loss.item()

  #           if i % self.print_freq == 0:
    print('Epoch {0} | Iter {1} | Average Loss {2:.3f} | Current Loss {3:.6f} | {4:.1f} ms/batch'.format(epoch + 1, i + 1, total_loss / (i + 1),loss.item(), 1000 * (time.time() - start) / (i + 1)),flush=True)
    total_loss / (i + 1)
    


  tr_avg_loss = total_loss
  print('-' * 85)
  print('Train Summary | End of Epoch {0} | Time {1:.2f}s | Train Loss {2:.3f}'.format(epoch + 1, time.time() - start, tr_avg_loss))
  print('-' * 85)
    # asdasdd


import matplotlib.pyplot as plt
plt.plot(LOSS)
